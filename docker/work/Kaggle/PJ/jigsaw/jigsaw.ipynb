{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c339bce-b077-408b-b010-2018757c46d4",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Challenge\n",
    "Identify and classify toxic online comments  \n",
    "[jifsaw competition page](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53960b91-9538-4726-96eb-13b88221955e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d73388-bd55-4efd-af85-6e85a92e4416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading jigsaw-toxic-comment-classification-challenge.zip to /work/Kaggle/PJ/jigsaw\n",
      " 99%|█████████████████████████████████████▌| 52.0M/52.6M [00:03<00:00, 7.68MB/s]\n",
      "100%|██████████████████████████████████████| 52.6M/52.6M [00:04<00:00, 13.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# setting up kaggle authentication\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# download kaggle dataset\n",
    "# !kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e46deb96-abec-444f-8269-77de2f212977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules required for file preparation\n",
    "from glob import glob\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea0f8ea8-29c1-4c81-b5a5-a8da7ba44c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unzip all zip files\n",
    "# files = glob(\"*.zip\")\n",
    "# for file in files:\n",
    "#     with ZipFile(file) as zip:\n",
    "#         zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "badbc98f-8565-4262-83f9-9de3edf80655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete all zip files\n",
    "# files = glob(\"*.zip\")        \n",
    "# for file in files:\n",
    "#     os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034cdc6-c9e9-4384-b87d-a81f0760de2c",
   "metadata": {},
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21c5ef15-8a9f-457b-a042-14e44eea7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import multiprocessing as mp\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from torchmetrics import AUROC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06ea7e48-7d89-45c7-b389-b81fc774a483",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d09f629-4f67-4092-8abc-d6717c470627",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, data, model_name, max_length, cache_tensors=False):\n",
    "        self.cache_tensors = cache_tensors\n",
    "        if self.cache_tensors:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.tokenized = tokenizer(\n",
    "                list(data[\"comment_text\"].values),\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            self.keys = list(self.tokenized.keys())\n",
    "        else:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            self.max_length = max_length\n",
    "            self.comments = list(data.comment_text.values)\n",
    "        self.labels = torch.as_tensor(data.values[:, 2:].astype(np.int_))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.cache_tensors:\n",
    "            inputs = {key: self.tokenized[key][idx] for key in self.keys}\n",
    "        else:\n",
    "            comment = self.comments[idx]\n",
    "            inputs = self.tokenizer(\n",
    "                comment,\n",
    "                add_special_tokens=True,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            # get rid of the batch dimension\n",
    "            inputs = {k: v[0] for k, v in inputs.items()}\n",
    "        inputs[\"labels\"] = self.labels[idx, :]\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b622ac3-a11d-49f2-92b9-6640c856c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawModel(pl.LightningModule):\n",
    "    def __init__(self, model_name, freeze_pretrained=True):\n",
    "        super().__init__()\n",
    "        self.hf_model = AutoModel.from_pretrained(model_name)\n",
    "        if freeze_pretrained:\n",
    "            for parameter in self.hf_model.parameters():\n",
    "                parameter.requires_grad = False\n",
    "        # try to autodetect output size based on last layer\n",
    "        out_size = list(self.hf_model.named_parameters())[-1][1].shape[0]\n",
    "        print(f\"Detected output size is {out_size}\")\n",
    "        self.head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_size, 6),\n",
    "        )\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        self.train_rocauc = AUROC(num_classes=6)\n",
    "        self.val_rocauc = AUROC(num_classes=6)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out = self.hf_model(**inputs)\n",
    "        out = self.head(out[\"pooler_output\"])\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-5)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, inputs):\n",
    "        x = {key: tensor for key, tensor in inputs.items() if key!=\"labels\"}\n",
    "        y = inputs[\"labels\"]\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_fn(y_hat, y.half())\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        self.train_rocauc(y_hat, y)\n",
    "        self.log('train_rocauc', self.train_rocauc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, inputs, *args):\n",
    "        x = {key: tensor for key, tensor in inputs.items() if key!=\"labels\"}\n",
    "        y = inputs[\"labels\"]\n",
    "        y_hat = self.forward(x)\n",
    "        self.val_rocauc(y_hat, y)\n",
    "        self.log('val_rocauc', self.val_rocauc, on_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8054f8dd-8e39-491b-90c7-f843ccf50f05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08beef06110e4f5e998bd1544459debe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fad6f9185c4fbdb2708094b0d3bfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1aebf02e9744438f2f154a060c6c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc04ca8e178f4d7b88dd86fc66966cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0c04d0b7db4fa6bff9ddab6c27d841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/anaconda3/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected output size is 768\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "You requested GPUs: [0]\n But your machine only has: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-04d7a2c3ee4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pooler_freeze\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0;31m trainer = pl.Trainer(\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/env_vars_connector.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, reload_dataloaders_every_epoch, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mgpu_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_select_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# init connectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_parse_devices\u001b[0;34m(gpus, auto_select_gpus, tpu_cores)\u001b[0m\n\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0;31m# TODO (@seannaren, @kaushikb11): Include IPU parsing logic here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m         \u001b[0mgpu_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m         \u001b[0mtpu_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tpu_cores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgpu_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_cores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\u001b[0m in \u001b[0;36mparse_gpu_ids\u001b[0;34m(gpus)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0m_check_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_sanitize_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/device_parser.py\u001b[0m in \u001b[0;36m_sanitize_gpu_ids\u001b[0;34m(gpus)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_available_gpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             raise MisconfigurationException(\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;34mf\"You requested GPUs: {gpus}\\n But your machine only has: {all_available_gpus}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             )\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: You requested GPUs: [0]\n But your machine only has: []"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "train_ds = JigsawDataset(train_data, model_name, max_length=256, cache_tensors=True)\n",
    "val_ds = JigsawDataset(val_data, model_name, max_length=256, cache_tensors=True)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    #persistent_workers=True\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    #persistent_workers=True\n",
    ")\n",
    "\n",
    "model = JigsawModel(model_name, freeze_pretrained=True)\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\n",
    "    \"lightning_logs/\",\n",
    "    name=\"jigsaw\",\n",
    "    version=\"pooler_freeze\"\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=500,\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    logger=tb_logger,\n",
    "    enable_checkpointing=False\n",
    ")\n",
    "trainer.fit(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5571d9-31c0-4b12-9e9d-38dc47b3c991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
